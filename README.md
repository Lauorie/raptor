# raptor
理解全文

假设我们有一个非常小的语言模型和一个简单的数据集:

1. 模型: 一个简单的语言模型,只能预测下一个单词。

2. 数据集: 只有一个句子 "The cat sat on the mat"

3. 词表: {"The", "cat", "sat", "on", "the", "mat"}

现在,让我们一步步计算困惑度:

1. 分词:
   首先,我们将句子分成单词: ["The", "cat", "sat", "on", "the", "mat"]

2. 计算概率:
   假设我们的模型对每个单词给出了以下预测概率:
   - P("The" | <start>) = 0.2
   - P("cat" | "The") = 0.1
   - P("sat" | "The cat") = 0.3
   - P("on" | "The cat sat") = 0.4
   - P("the" | "The cat sat on") = 0.5
   - P("mat" | "The cat sat on the") = 0.2

3. 计算负对数似然:
   对每个概率取负对数:
   - -log(0.2) ≈ 1.61
   - -log(0.1) ≈ 2.30
   - -log(0.3) ≈ 1.20
   - -log(0.4) ≈ 0.92
   - -log(0.5) ≈ 0.69
   - -log(0.2) ≈ 1.61

4. 计算平均负对数似然:
   (1.61 + 2.30 + 1.20 + 0.92 + 0.69 + 1.61) / 6 ≈ 1.39

5. 计算困惑度:
   perplexity = e^(平均负对数似然) = e^1.39 ≈ 4.01

所以,这个模型在这个简单句子上的困惑度约为4.01。

解释:
- 困惑度可以被理解为模型在每个位置上平均需要从多少个选项中猜测。
- 困惑度越低,表示模型的预测越准确。在这个例子中,4.01意味着模型在每个位置上平均需要从约4个选项中选择。
- 理想情况下,一个完美的模型会在每个位置都100%确定下一个词,这样困惑度就会是1。

在实际的代码中,这个过程会在更大的数据集上进行,并且使用滑动窗口来处理长文本。但基本原理是一样的:计算模型对每个单词的预测概率,然后用这些概率来计算整体的困惑度。
